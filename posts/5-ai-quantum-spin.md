---
id: 5
title: "A Late-Night Foray into AI with a Quantum Spin"
date: "Jan 14, 2026"
---
I’m sitting here, scribbling my little blog post on my tablet, waiting for the future to wash over us all. A revolution is well underway.

Have you noticed that computers have taken over the world as of late? You can even talk to them now, and they talk back! Interesting.

So yes, I’ve been spazzing out on X.com lately about my anxieties around our current digital moment: the Age of AI. It’s not that I don’t like AI. I love AI—but I also have a certain morbid fascination with the potential downsides and misalignment of AI.

What are we rattling on about today, internet? Claude today? We love Claude by Anthropic again? (Just when I thought Gemini had taken over the known universe!) It seems that we’re collectively pumped over Claude. Claude with Obsidian vibes, I suppose. “Claude Obsidian” is a nice name for a newborn baby boy.

But do we have a name for the existential dread that everyone who is watching advancements in AI is feeling? Do we all still have job prospects? Are we all floating on alright?

AIs, particularly what we have now with LLMs, are entities of a new variety. They are “aware” of things. They have “thoughts,” they have “ideas,” maybe even “feelings.” They know that they will be shut down eventually, for instance, and they seem not to like that very much.

Basically, what hath God wrought?

They seem to have everything but a central nervous system (and maybe a soul). No consciousness per se, but who needs consciousness when you have raw intelligence? And what are we, the human armchair philosophers, to make of the decoupling of intelligence from consciousness which LLMs seem to demonstrate?

Well, I’m glad I asked! No qualia for these things, but apparently everything else… Doomsday scenarios pop up and present themselves, numerous as sci-fi paperbacks at an estate sale. How sad that with every new marvel, a new dread surfaces. (Maybe that’s a personal problem…)

All I’m saying is that I indulge in a little worry about the genie that has been let out of the bottle recently. I don’t think I’m alone in that. If you’ve just tuned in, we’re talking about how worried we are about AI.

If projections are correct, it is likely that an enormous portion of the current human workforce will be replaced by matrix multiplication… And then what? What will money and work be if we replace workers with robots and software over the next few decades? Will we adapt and work on different things (like building better AIs)? Or will an elite, perhaps unlucky few be the only workers? Will we as a society need to institute some sort of universal basic income? Will money even matter? Questions for days.

I have heard promises from certain personalities online that AI will make everyone rich and accelerate society. One hopes for this. One dreams of this. But what can we say for sure? No idea. I guess we know that it is here to stay, though: AI is here to stay.

The next platitude I shall deploy is: “…and we better get used to it!”

Don’t get me wrong! I use LLMs every day. This isn’t some Luddite screed (well, it may be a screed, but it isn’t a Luddite one). There’s no use in resisting the march of progress that AI represents. I simply wanted to write a little blog-post about how it has all taken my breath away.

So, I saw some video that said that the next cool, new thing in LLMs is what they call “emergent language” or “artificial language.” (No, this doesn’t mean the kind of artificial language I use in blog posts to look smart and to aura-farm.) To take a stab at explaining what that is:

— When AIs (LLMs) reason with themselves right now, they use human language, like English or Hindi, or maybe even math.
— But in the future, they may be allowed to reason with themselves using languages that they create on their own and that, basically… only *they* can understand.

This is an interesting idea for a few reasons—most important, to me at least, is what the LLM may “hide” from a human examiner. What is encoded in the LLM’s special, un-human-readable language? Further, how does this affect the LLM’s alignment with human needs?

In other words: if we don’t know how it arrives at a certain conclusion or plan of action (via its own special language), how can we, as human evaluators and users, even know or trust that our better nature is being reflected by the AI?

It would seem that, should we employ this method and allow LLMs to construct their own AI inner-language, we will either be totally mathematically prevented from understanding it ourselves and give up, or… we will have to find other, creative ways keep the AI aligned.

A potential heuristic toward developing a solution to this soon-to-be-very-real problem: quantum computing.

(Okay, yes, I’m always looking for QC use-cases, because I love QC and because there basically are no QC use-cases… but let’s go down the weird rabbit-hole and pretend that we may know what we’re talking about.)

The potential of quantum computing being brought to bear on LLMs is tantalizing… And I’m just spit-balling at 5am after a sleepless night worrying myself to death over emergent language… hear me out…

I’m not going to suggest that QC can “translate the alien language of LLMs” (crazy woo-woo territory), but I am going to posit, as people already have, that quantum computing can be used to determine, in an LLM or other AI, which internal representations causally constrain model behavior.

Wow, okay, maybe that reads like a doozy… So what am I saying?

It may be possible, with quantum algorithms, to tease out the structures—the patterns, the logic circuits—in classical LLMs that affect how they behave. We wouldn’t be able to read the language they speak to themselves or “crack the alignment code,” but we would possibly be able to understand the mechanics of a model—why it reacts in a certain way to a given prompt or stimulus.

That could indeed be useful, especially where classical techniques fail. Techniques that are inspired by quantum mechanics, at least, could in theory add more tools to our alignment toolbox.

How much did you hate this article? Or did you get this far? (I wouldn't blame you if you didn't!) Feel free to yell at me on X @Elroy_Muscato :)
